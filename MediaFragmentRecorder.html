<!DOCTYPE html>
<html>
<head>
  <title>Record media fragments to single webm video using RTCPeerConnection(), RTCRtpSender.replaceTrack(), MediaStream addtrack event, MediaRecorder()</title>
</head>
<body>
  <h1 id="click">click</h1>
  <video id="playlist" src="" controls="true" autoplay="true"></video>
  <script>
    const captureStream = mediaElement =>
      !!mediaElement.mozCaptureStream ? mediaElement.mozCaptureStream() : mediaElement.captureStream();
    const createMediaStreamTracks = _ => {
      const audioContext = new AudioContext();
      const audioStreamDestination = audioContext.createMediaStreamDestination();
      let mediaStream = audioStreamDestination.stream;
      const [audioTrack] = audioStreamDestination.stream.getAudioTracks();
      const canvas = document.createElement("canvas");
      const ctx = canvas.getContext("2d");
      const canvasStream = canvas.captureStream(0);
      const [videoTrack] = canvasStream.getVideoTracks();
      mediaStream.addTrack(videoTrack);
      let raf;
      const draw = async() => {
        ctx.fillStyle = "black";
        ctx.fillRect(0, 0, width, height);
        requestFrame();
        requestAnimationFrame(draw)
      };
      console.log(canvasStream.requestFrame);
      const requestFrame = _ => canvasStream.requestFrame ? canvasStream.requestFrame() : videoTrack.requestFrame();
      raf = requestAnimationFrame(draw);
      return {
        mediaStream, audioTrack, videoTrack, audioContext, audioStreamDestination, raf
      };
    }
    const kinds = ["video", "audio"];
    const width = 320;
    const height = 240;
    const videoConstraints = {
      frameRate: 30,
      resizeMode: "crop-and-scale",
      width,
      height
    };
    const blobURLS = [];
    const urls = Promise.all([{
      src: "https://upload.wikimedia.org/wikipedia/commons/a/a4/Xacti-AC8EX-Sample_video-001.ogv",
      from: 0,
      to: 4
    }, {
      from: 10,
      to: 20,
      src: "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=10,20"
    }, {
      from: 55,
      to: 60,
      src: "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4"
    }, {
      from: 0,
      to: 5,
      src: "https://raw.githubusercontent.com/w3c/web-platform-tests/master/media-source/mp4/test.mp4"
    }, {
      from: 0,
      to: 5,
      src: "https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4"
    }, {
      from: 0,
      to: 5,
      src: "https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerJoyrides.mp4"
    }, {
      from: 0,
      to: 6,
      src: "https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4#t=0,6"
    }].map(async({
      from,
      to,
      src
    }) => {
      try {
        const request = await fetch(src);
        const blob = await request.blob();
        const blobURL = URL.createObjectURL(blob);
        blobURLS.push(blobURL);
        const url = new URL(src);
        console.log(url.hash);
        return blobURL + (url.hash || `#t=${from},${to}`);
      } catch (e) {
        throw e;
      }
    }));
    let playlist = document.getElementById("playlist");
    playlist.width = width;
    playlist.height = height;
    let recorder;
    let resolveResult;
    let result;
    const promiseResult = new Promise(resolve => resolveResult = resolve);
    document.getElementById("click")
      .addEventListener("click", async e => {
        try {
          // create audio and video MediaStreamTrack
          let {
            mediaStream, audioTrack, videoTrack, raf, audioContext
          } = createMediaStreamTracks();
          try {
            await videoTrack.applyConstraints(videoConstraints);
          } catch (e) {
            console.error(e, e.name === "OverconstrainedError");
          }
          console.log("initial MediaStream, audio and video MediaStreamTracks", mediaStream, mediaStream.getTracks());

          const fromLocalPeerConnection = new RTCPeerConnection();
          const toLocalPeerConnection = new RTCPeerConnection();
          const fromConnection = new Promise(resolve => fromLocalPeerConnection.addEventListener("icecandidate", async e => {
            console.log("from", e);
            try {
              resolve(toLocalPeerConnection.addIceCandidate(e.candidate ? e.candidate : null));
            } catch (e) {
              console.error(e);
            }
          }, {
            once: true
          }));
          const toConnection = new Promise(resolve => toLocalPeerConnection.addEventListener("icecandidate", async e => {
            console.log("to", e);
            try {
              resolve(fromLocalPeerConnection.addIceCandidate(e.candidate ? e.candidate : null));
            } catch (e) {
              console.error(e);
            }
          }, {
            once: true
          }));
          fromLocalPeerConnection.addEventListener("negotiationneeded", e => {
            console.log(e);
          });
          toLocalPeerConnection.addEventListener("negotiationneeded", e => {
            console.log(e);
          });
          const unmutePromises = [];
          const mediaStreamTrackPromise = new Promise(resolve => {
            toLocalPeerConnection.addEventListener("track", event => {
              unmutePromises.push(new Promise(res => event.track.addEventListener("unmute", e => {
                console.log(e);
                res()
              })));
              console.log("track event", event);
              kinds.splice(kinds.findIndex(({
                kind
              }) => kind === event.track.kind), 1);
              // Wait for both "track" events
              if (kinds.length === 0) {
                const {
                  streams: [stream]
                } = event;
                console.log(stream);
                // Reassign stream to initial MediaStream reference                                                           
                mediaStream = stream;
                resolve();
              }
            });
          });
          // Add initial audio and video MediaStreamTrack to PeerConnection, pass initial MediaStream
          const {
            sender: audioSender,
            receiver: audioReceiver
          } = fromLocalPeerConnection.addTransceiver(audioTrack, {
            streams: [mediaStream]
          });
          const {
            sender: videoSender,
            receiver: videoReceiver
          } = fromLocalPeerConnection.addTransceiver(videoTrack, {
            streams: [mediaStream]
          });
          console.log(audioSender, videoSender, audioReceiver, videoReceiver);
          const offer = await fromLocalPeerConnection.createOffer();
          await toLocalPeerConnection.setRemoteDescription(offer);
          await fromLocalPeerConnection.setLocalDescription(toLocalPeerConnection.remoteDescription);
          const answer = await toLocalPeerConnection.createAnswer();
          await fromLocalPeerConnection.setRemoteDescription(answer);
          await toLocalPeerConnection.setLocalDescription(fromLocalPeerConnection.remoteDescription);
          let media = await urls;
          await fromConnection;
          await toConnection;
          await mediaStreamTrackPromise;
          console.log(audioSender, videoSender, mediaStream);
          const playlistStream = captureStream(playlist);
          playlistStream.addEventListener("addtrack", async e => {
            console.log(e.type, e.track);
            if (e.track.kind === "video") {
              try {
                await e.track.applyConstraints(videoConstraints);
              } catch (e) {
                console.error(e, e.name === "OverconstrainedError");
              }
              await videoSender.replaceTrack(e.track);
            } else {
              await audioSender.replaceTrack(e.track);
            }
            if (!recorder) {
              recorder = new MediaRecorder(mediaStream, {
                mimeType: "video/webm;codecs=vp8,opus",
                audioBitsPerSecond: 128000,
                videoBitsPerSecond: 2500000
              });
              recorder.addEventListener("start", e => {
                console.log(e, e.target.stream.getTracks(), audioReceiver.track, videoReceiver.track);
                cancelAnimationFrame(raf);
              });
              recorder.addEventListener("stop", e => {
                console.log(e);
                resolveResult(result);
              });
              recorder.addEventListener("dataavailable", e => {
                console.log(e.data);
                result = e.data;
              });
              recorder.addEventListener("error", e => {
                console.log(e);
              });
              recorder.addEventListener("pause", e => {
                console.log(e, e.target.stream.getTracks());
              });
            }
            if (recorder.state === "inactive") {
              recorder.start();
            }

            e.track.addEventListener("mute", e => {
              console.log(e.type);
            });
            e.track.addEventListener("unmute", e => {
              console.log(e.type);
            });
            e.track.addEventListener("ended", e => {
              console.log(e.type);
            });

          });
          await Promise.all(unmutePromises);
          // Chromium outputs Blob with size 0 Blob {size: 0, type: "video/webm;codecs=vp8,opus"}
          // if mediaStream is not attached to a <video> element, set srcObject to a <video> element
          // https://bugs.chromium.org/p/chromium/issues/detail?id=952700
          if (!playlist.mozCaptureStream) {
            const clone = playlist.cloneNode();
            clone.muted = true;
            clone.srcObject = mediaStream;
          }

          playlist.addEventListener("play", async e => {
            console.log(e, e.target.readyState);
          });

          for (const blobURL of media) {
            await new Promise(async resolve => {
              playlist.addEventListener("pause", e => {
                console.log(e);
                resolve();
              }, {
                once: true
              });
              playlist.src = blobURL;
            });
          }
          recorder.stop();
          let blob = await promiseResult;
          blobURLS.forEach(blobURL => URL.revokeObjectURL(blobURL));
          [audioTrack, videoTrack, ...mediaStream.getTracks()]
          .forEach(track => {
            track.stop();
            track.enabled = false;
            console.log(track);
          });
          fromLocalPeerConnection.close();
          toLocalPeerConnection.close();
          await audioContext.close();
          console.log(blob);
          playlist.remove();
          const videoStream = document.createElement("video");
          videoStream.addEventListener("canplaythrough", e => {
            console.log(videoStream.duration, videoStream.seekable.end(0));
          });
          videoStream.width = width;
          videoStream.height = height;
          videoStream.controls = true;
          document.body.appendChild(videoStream);
          videoStream.src = URL.createObjectURL(blob);
        } catch (e) {
          console.error(e);
          console.trace();
        };
      }, {
        once: true
      });
  </script>
</body>
</html>
